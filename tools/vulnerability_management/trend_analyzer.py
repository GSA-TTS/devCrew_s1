"""
Trend Analyzer - Metrics over time, MTTR calculation, security debt analysis.

Tracks vulnerability trends and calculates security metrics.
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from .remediation_tracker import RemediationStatus, RemediationTask, RemediationTracker
from .vulnerability_aggregator import Severity, Vulnerability


@dataclass
class TrendDataPoint:
    """Single data point in trend analysis."""

    timestamp: datetime
    total_open: int
    total_closed: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    new_findings: int
    resolved_findings: int


@dataclass
class SecurityDebtItem:
    """Represents security debt from unresolved vulnerabilities."""

    vulnerability: Vulnerability
    age_days: int
    estimated_effort_hours: float
    risk_score: float


class TrendAnalyzer:
    """Analyze vulnerability trends and metrics over time."""

    # Estimated remediation effort by severity (hours)
    EFFORT_ESTIMATES = {
        Severity.CRITICAL: 16,
        Severity.HIGH: 8,
        Severity.MEDIUM: 4,
        Severity.LOW: 2,
        Severity.INFO: 1,
    }

    def __init__(self) -> None:
        """Initialize analyzer."""
        self._historical_data: List[TrendDataPoint] = []
        self._vulnerability_history: Dict[str, List[Dict[str, Any]]] = {}

    def record_snapshot(
        self,
        vulnerabilities: List[Vulnerability],
        tasks: List[RemediationTask],
        timestamp: Optional[datetime] = None,
    ) -> TrendDataPoint:
        """Record current state as historical data point."""
        ts = timestamp or datetime.now()

        # Count open/closed tasks
        open_count = sum(
            1 for t in tasks
            if t.status not in (RemediationStatus.RESOLVED, RemediationStatus.FALSE_POSITIVE)
        )
        closed_count = sum(
            1 for t in tasks
            if t.status in (RemediationStatus.RESOLVED, RemediationStatus.FALSE_POSITIVE)
        )

        # Count by severity
        severity_counts = {s: 0 for s in Severity}
        for vuln in vulnerabilities:
            severity_counts[vuln.severity] += 1

        # Calculate new/resolved since last snapshot
        new_findings = 0
        resolved_findings = 0
        if self._historical_data:
            last = self._historical_data[-1]
            new_findings = max(0, len(vulnerabilities) - (last.total_open + last.total_closed))
            resolved_findings = max(0, closed_count - last.total_closed)

        data_point = TrendDataPoint(
            timestamp=ts,
            total_open=open_count,
            total_closed=closed_count,
            critical_count=severity_counts[Severity.CRITICAL],
            high_count=severity_counts[Severity.HIGH],
            medium_count=severity_counts[Severity.MEDIUM],
            low_count=severity_counts[Severity.LOW],
            new_findings=new_findings,
            resolved_findings=resolved_findings,
        )

        self._historical_data.append(data_point)
        return data_point

    def calculate_mttr(
        self, tasks: List[RemediationTask], severity: Optional[Severity] = None
    ) -> float:
        """Calculate Mean Time To Remediation (MTTR) in days."""
        resolved_tasks = [
            t for t in tasks
            if t.status == RemediationStatus.RESOLVED and t.time_to_resolution
        ]

        if severity:
            resolved_tasks = [
                t for t in resolved_tasks if t.vulnerability.severity == severity
            ]

        if not resolved_tasks:
            return 0.0

        total_days = sum(t.time_to_resolution.days for t in resolved_tasks if t.time_to_resolution)
        return round(total_days / len(resolved_tasks), 2)

    def calculate_mttr_by_severity(
        self, tasks: List[RemediationTask]
    ) -> Dict[str, float]:
        """Calculate MTTR for each severity level."""
        return {
            severity.value: self.calculate_mttr(tasks, severity)
            for severity in Severity
        }

    def calculate_security_debt(
        self, vulnerabilities: List[Vulnerability], tasks: List[RemediationTask]
    ) -> Dict[str, Any]:
        """Calculate security debt from unresolved vulnerabilities."""
        # Find open vulnerabilities
        resolved_fingerprints = {
            t.vulnerability.fingerprint
            for t in tasks
            if t.status in (RemediationStatus.RESOLVED, RemediationStatus.FALSE_POSITIVE)
        }

        open_vulns = [
            v for v in vulnerabilities if v.fingerprint not in resolved_fingerprints
        ]

        debt_items: List[SecurityDebtItem] = []
        total_effort = 0.0
        total_risk = 0.0

        for vuln in open_vulns:
            age = (datetime.now() - vuln.discovered_at).days
            effort = self.EFFORT_ESTIMATES.get(vuln.severity, 4)

            # Risk increases with age
            age_multiplier = 1 + (age / 30) * 0.1  # 10% increase per month
            risk = (vuln.cvss_score or 5.0) * age_multiplier

            debt_items.append(SecurityDebtItem(
                vulnerability=vuln,
                age_days=age,
                estimated_effort_hours=effort,
                risk_score=round(risk, 2),
            ))

            total_effort += effort
            total_risk += risk

        return {
            "total_open_vulnerabilities": len(open_vulns),
            "total_estimated_effort_hours": round(total_effort, 1),
            "total_risk_score": round(total_risk, 2),
            "average_age_days": round(
                sum(d.age_days for d in debt_items) / len(debt_items), 1
            ) if debt_items else 0,
            "by_severity": {
                severity.value: {
                    "count": sum(1 for d in debt_items if d.vulnerability.severity == severity),
                    "effort_hours": sum(
                        d.estimated_effort_hours
                        for d in debt_items
                        if d.vulnerability.severity == severity
                    ),
                }
                for severity in Severity
            },
            "top_debt_items": [
                {
                    "vuln_id": d.vulnerability.vuln_id,
                    "title": d.vulnerability.title,
                    "age_days": d.age_days,
                    "effort_hours": d.estimated_effort_hours,
                    "risk_score": d.risk_score,
                }
                for d in sorted(debt_items, key=lambda x: x.risk_score, reverse=True)[:10]
            ],
        }

    def get_trend(
        self, period_days: int = 30
    ) -> Dict[str, Any]:
        """Get vulnerability trend over specified period."""
        if not self._historical_data:
            return {"error": "No historical data available"}

        cutoff = datetime.now() - timedelta(days=period_days)
        period_data = [d for d in self._historical_data if d.timestamp >= cutoff]

        if len(period_data) < 2:
            return {"error": "Insufficient data for trend analysis"}

        first = period_data[0]
        last = period_data[-1]

        open_change = last.total_open - first.total_open
        open_change_pct = (open_change / first.total_open * 100) if first.total_open > 0 else 0

        return {
            "period_days": period_days,
            "data_points": len(period_data),
            "start_date": first.timestamp.isoformat(),
            "end_date": last.timestamp.isoformat(),
            "open_vulnerabilities": {
                "start": first.total_open,
                "end": last.total_open,
                "change": open_change,
                "change_percent": round(open_change_pct, 2),
            },
            "total_new_findings": sum(d.new_findings for d in period_data),
            "total_resolved": sum(d.resolved_findings for d in period_data),
            "trend_direction": "improving" if open_change < 0 else "worsening" if open_change > 0 else "stable",
            "by_severity": {
                "critical": {
                    "start": first.critical_count,
                    "end": last.critical_count,
                    "change": last.critical_count - first.critical_count,
                },
                "high": {
                    "start": first.high_count,
                    "end": last.high_count,
                    "change": last.high_count - first.high_count,
                },
            },
        }

    def calculate_velocity(
        self, tasks: List[RemediationTask], period_days: int = 30
    ) -> Dict[str, Any]:
        """Calculate remediation velocity (vulns resolved per week)."""
        cutoff = datetime.now() - timedelta(days=period_days)

        resolved_in_period = [
            t for t in tasks
            if t.status == RemediationStatus.RESOLVED
            and t.resolved_at
            and t.resolved_at >= cutoff
        ]

        weeks = period_days / 7
        velocity = len(resolved_in_period) / weeks if weeks > 0 else 0

        return {
            "period_days": period_days,
            "resolved_count": len(resolved_in_period),
            "velocity_per_week": round(velocity, 2),
            "by_severity": {
                severity.value: sum(
                    1 for t in resolved_in_period
                    if t.vulnerability.severity == severity
                )
                for severity in Severity
            },
        }

    def forecast_debt_reduction(
        self,
        current_debt: Dict[str, Any],
        velocity: Dict[str, Any],
        target_weeks: int = 12,
    ) -> Dict[str, Any]:
        """Forecast security debt reduction based on current velocity."""
        weekly_velocity = velocity.get("velocity_per_week", 0)
        current_open = current_debt.get("total_open_vulnerabilities", 0)

        if weekly_velocity <= 0:
            weeks_to_zero = float("inf")
        else:
            weeks_to_zero = current_open / weekly_velocity

        projected_open = max(0, current_open - (weekly_velocity * target_weeks))

        return {
            "current_open": current_open,
            "weekly_velocity": weekly_velocity,
            "target_weeks": target_weeks,
            "projected_open_after_target": round(projected_open),
            "weeks_to_zero_debt": round(weeks_to_zero, 1) if weeks_to_zero != float("inf") else None,
            "reduction_percent": round(
                (current_open - projected_open) / current_open * 100, 1
            ) if current_open > 0 else 0,
        }

    def generate_metrics_report(
        self,
        vulnerabilities: List[Vulnerability],
        tasks: List[RemediationTask],
    ) -> Dict[str, Any]:
        """Generate comprehensive metrics report."""
        mttr = self.calculate_mttr_by_severity(tasks)
        debt = self.calculate_security_debt(vulnerabilities, tasks)
        velocity = self.calculate_velocity(tasks)
        forecast = self.forecast_debt_reduction(debt, velocity)

        return {
            "generated_at": datetime.now().isoformat(),
            "summary": {
                "total_vulnerabilities": len(vulnerabilities),
                "open_vulnerabilities": debt["total_open_vulnerabilities"],
                "overall_mttr_days": self.calculate_mttr(tasks),
                "security_debt_hours": debt["total_estimated_effort_hours"],
            },
            "mttr_by_severity": mttr,
            "security_debt": debt,
            "remediation_velocity": velocity,
            "forecast": forecast,
            "trend": self.get_trend() if self._historical_data else None,
        }

    def export_metrics(self, file_path: str) -> None:
        """Export historical metrics to JSON file."""
        import json

        data = {
            "exported_at": datetime.now().isoformat(),
            "data_points": [
                {
                    "timestamp": dp.timestamp.isoformat(),
                    "total_open": dp.total_open,
                    "total_closed": dp.total_closed,
                    "critical_count": dp.critical_count,
                    "high_count": dp.high_count,
                    "medium_count": dp.medium_count,
                    "low_count": dp.low_count,
                    "new_findings": dp.new_findings,
                    "resolved_findings": dp.resolved_findings,
                }
                for dp in self._historical_data
            ],
        }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2)
